{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BuzzFeed_fake_news_content.csv\tPolitiFact_fake_news_content.csv\r\n",
      "BuzzFeedNews.txt\t\tPolitiFactNews.txt\r\n",
      "BuzzFeedNewsUser.txt\t\tPolitiFactNewsUser.txt\r\n",
      "BuzzFeed_real_news_content.csv\tPolitiFact_real_news_content.csv\r\n",
      "BuzzFeedUserFeature.mat\t\tPolitiFactUserFeature.mat\r\n",
      "BuzzFeedUser.txt\t\tPolitiFactUser.txt\r\n",
      "BuzzFeedUserUser.txt\t\tPolitiFactUserUser.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BuzzFeedNews.txt newsid list, index by the row num. For example, 'PolitiFactReal_1' is in the 1st row, so it's corresponding to index 1.\n",
    "* BuzzFeedNewsUser.txt News-User relationship in BuzzFeed. For example, '240 1 1' means news 240 is posted/spreaded by user 1 for 1 time.\n",
    "* BuzzFeedUser.txt user_name list : index by the row num. For example, 'f4b46be21c2f553811cc8a73c4f0ff05' is in the 1st row, so so it's corresponding to index 1.\n",
    "* BuzzFeedUserFeature.mat Latent represenation of user features from BuzzFeed dataset as MATLAB file\n",
    "* BuzzFeedUserUser.txt User-User relationship. For example, '1589 1' means user 1589 is following user 1;\n",
    "* BuzzFeed_fake_news_content.csv BuzzFeed Fake news content meta data including news source, headline, image, bodytext, publishdata, etc\n",
    "* BuzzFeed_real_news_content.csv BuzzFeed Real news content meta data including news source, headline, image, bodytext, publishdata, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='dataset/'\n",
    "\n",
    "BFNews=pd.read_csv(path+'BuzzFeedNews.txt', header=None)\n",
    "BFNewsUser=pd.read_csv(path+'BuzzFeedNewsUser.txt', header=None, sep='\\t')\n",
    "BFreal_news=pd.read_csv(path+'BuzzFeed_real_news_content.csv')\n",
    "BFUser=pd.read_csv(path+'BuzzFeedUser.txt', header=None)\n",
    "BFUserUser=pd.read_csv(path+'BuzzFeedUserUser.txt', header=None, sep='\\t')\n",
    "BFfake_news=pd.read_csv(path+'BuzzFeed_fake_news_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 182 entries, 0 to 90\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              182 non-null    object\n",
      " 1   title           182 non-null    object\n",
      " 2   text            182 non-null    object\n",
      " 3   url             174 non-null    object\n",
      " 4   top_img         172 non-null    object\n",
      " 5   authors         141 non-null    object\n",
      " 6   source          174 non-null    object\n",
      " 7   publish_date    133 non-null    object\n",
      " 8   movies          25 non-null     object\n",
      " 9   images          172 non-null    object\n",
      " 10  canonical_link  170 non-null    object\n",
      " 11  meta_data       182 non-null    object\n",
      "dtypes: object(12)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([BFreal_news, BFfake_news],axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>top_img</th>\n",
       "      <th>authors</th>\n",
       "      <th>source</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>movies</th>\n",
       "      <th>images</th>\n",
       "      <th>canonical_link</th>\n",
       "      <th>meta_data</th>\n",
       "      <th>article</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real_1-Webpage</td>\n",
       "      <td>Another Terrorist Attack in NYC…Why Are we STI...</td>\n",
       "      <td>On Saturday, September 17 at 8:30 pm EST, an e...</td>\n",
       "      <td>http://eaglerising.com/36942/another-terrorist...</td>\n",
       "      <td>http://eaglerising.com/wp-content/uploads/2016...</td>\n",
       "      <td>View All Posts,Leonora Cravotta</td>\n",
       "      <td>http://eaglerising.com</td>\n",
       "      <td>{'$date': 1474528230000}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://constitution.com/wp-content/uploads/201...</td>\n",
       "      <td>http://eaglerising.com/36942/another-terrorist...</td>\n",
       "      <td>{\"description\": \"\\u201cWe believe at this poin...</td>\n",
       "      <td>Another Terrorist Attack in NYC…Why Are we STI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real_10-Webpage</td>\n",
       "      <td>Donald Trump: Drugs a 'Very, Very Big Factor' ...</td>\n",
       "      <td>Less than a day after protests over the police...</td>\n",
       "      <td>http://abcn.ws/2d4lNn9</td>\n",
       "      <td>http://a.abcnews.com/images/Politics/AP_donald...</td>\n",
       "      <td>More Candace,Adam Kelsey,Abc News,More Adam</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.googleadservices.com/pagead/convers...</td>\n",
       "      <td>http://abcnews.go.com/Politics/donald-trump-dr...</td>\n",
       "      <td>{\"fb_title\": \"Trump: Drugs a 'Very, Very Big F...</td>\n",
       "      <td>Donald Trump: Drugs a 'Very, Very Big Factor' ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Real_11-Webpage</td>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>http://rightwingnews.com/barack-obama/obama-un...</td>\n",
       "      <td>http://rightwingnews.com/wp-content/uploads/20...</td>\n",
       "      <td>Cassy Fiano</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>{'$date': 1474476044000}</td>\n",
       "      <td>https://www.youtube.com/embed/ji6pl5Vwrvk</td>\n",
       "      <td>http://rightwingnews.com/wp-content/uploads/20...</td>\n",
       "      <td>http://rightwingnews.com/barack-obama/obama-un...</td>\n",
       "      <td>{\"googlebot\": \"noimageindex\", \"og\": {\"site_nam...</td>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real_12-Webpage</td>\n",
       "      <td>Trump vs. Clinton: A Fundamental Clash over Ho...</td>\n",
       "      <td>Getty Images Wealth Of Nations Trump vs. Clint...</td>\n",
       "      <td>http://politi.co/2de2qs0</td>\n",
       "      <td>http://static.politico.com/e9/11/6144cdc24e319...</td>\n",
       "      <td>Jack Shafer,Erick Trickey,Zachary Karabell</td>\n",
       "      <td>http://politi.co</td>\n",
       "      <td>{'$date': 1474974420000}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://static.politico.com/dims4/default/8a1c...</td>\n",
       "      <td>http://www.politico.com/magazine/story/2016/09...</td>\n",
       "      <td>{\"description\": \"He sees it as zero-sum. She b...</td>\n",
       "      <td>Trump vs. Clinton: A Fundamental Clash over Ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Real_13-Webpage</td>\n",
       "      <td>President Obama Vetoes 9/11 Victims Bill, Sett...</td>\n",
       "      <td>President Obama today vetoed a bill that would...</td>\n",
       "      <td>http://abcn.ws/2dh2NFs</td>\n",
       "      <td>http://a.abcnews.com/images/US/AP_Obama_BM_201...</td>\n",
       "      <td>John Parkinson,More John,Abc News,More Alexander</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.googleadservices.com/pagead/convers...</td>\n",
       "      <td>http://abcnews.go.com/Politics/president-obama...</td>\n",
       "      <td>{\"fb_title\": \"President Obama Vetoes 9/11 Vict...</td>\n",
       "      <td>President Obama Vetoes 9/11 Victims Bill, Sett...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "0   Real_1-Webpage  Another Terrorist Attack in NYC…Why Are we STI...   \n",
       "1  Real_10-Webpage  Donald Trump: Drugs a 'Very, Very Big Factor' ...   \n",
       "2  Real_11-Webpage  Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3  Real_12-Webpage  Trump vs. Clinton: A Fundamental Clash over Ho...   \n",
       "4  Real_13-Webpage  President Obama Vetoes 9/11 Victims Bill, Sett...   \n",
       "\n",
       "                                                text  \\\n",
       "0  On Saturday, September 17 at 8:30 pm EST, an e...   \n",
       "1  Less than a day after protests over the police...   \n",
       "2  Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3  Getty Images Wealth Of Nations Trump vs. Clint...   \n",
       "4  President Obama today vetoed a bill that would...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://eaglerising.com/36942/another-terrorist...   \n",
       "1                             http://abcn.ws/2d4lNn9   \n",
       "2  http://rightwingnews.com/barack-obama/obama-un...   \n",
       "3                           http://politi.co/2de2qs0   \n",
       "4                             http://abcn.ws/2dh2NFs   \n",
       "\n",
       "                                             top_img  \\\n",
       "0  http://eaglerising.com/wp-content/uploads/2016...   \n",
       "1  http://a.abcnews.com/images/Politics/AP_donald...   \n",
       "2  http://rightwingnews.com/wp-content/uploads/20...   \n",
       "3  http://static.politico.com/e9/11/6144cdc24e319...   \n",
       "4  http://a.abcnews.com/images/US/AP_Obama_BM_201...   \n",
       "\n",
       "                                            authors                    source  \\\n",
       "0                   View All Posts,Leonora Cravotta    http://eaglerising.com   \n",
       "1       More Candace,Adam Kelsey,Abc News,More Adam            http://abcn.ws   \n",
       "2                                       Cassy Fiano  http://rightwingnews.com   \n",
       "3        Jack Shafer,Erick Trickey,Zachary Karabell          http://politi.co   \n",
       "4  John Parkinson,More John,Abc News,More Alexander            http://abcn.ws   \n",
       "\n",
       "               publish_date                                     movies  \\\n",
       "0  {'$date': 1474528230000}                                        NaN   \n",
       "1                       NaN                                        NaN   \n",
       "2  {'$date': 1474476044000}  https://www.youtube.com/embed/ji6pl5Vwrvk   \n",
       "3  {'$date': 1474974420000}                                        NaN   \n",
       "4                       NaN                                        NaN   \n",
       "\n",
       "                                              images  \\\n",
       "0  http://constitution.com/wp-content/uploads/201...   \n",
       "1  http://www.googleadservices.com/pagead/convers...   \n",
       "2  http://rightwingnews.com/wp-content/uploads/20...   \n",
       "3  https://static.politico.com/dims4/default/8a1c...   \n",
       "4  http://www.googleadservices.com/pagead/convers...   \n",
       "\n",
       "                                      canonical_link  \\\n",
       "0  http://eaglerising.com/36942/another-terrorist...   \n",
       "1  http://abcnews.go.com/Politics/donald-trump-dr...   \n",
       "2  http://rightwingnews.com/barack-obama/obama-un...   \n",
       "3  http://www.politico.com/magazine/story/2016/09...   \n",
       "4  http://abcnews.go.com/Politics/president-obama...   \n",
       "\n",
       "                                           meta_data  \\\n",
       "0  {\"description\": \"\\u201cWe believe at this poin...   \n",
       "1  {\"fb_title\": \"Trump: Drugs a 'Very, Very Big F...   \n",
       "2  {\"googlebot\": \"noimageindex\", \"og\": {\"site_nam...   \n",
       "3  {\"description\": \"He sees it as zero-sum. She b...   \n",
       "4  {\"fb_title\": \"President Obama Vetoes 9/11 Vict...   \n",
       "\n",
       "                                             article  news_type  \n",
       "0  Another Terrorist Attack in NYC…Why Are we STI...          1  \n",
       "1  Donald Trump: Drugs a 'Very, Very Big Factor' ...          1  \n",
       "2  Obama To UN: ‘Giving Up Liberty, Enhances Secu...          1  \n",
       "3  Trump vs. Clinton: A Fundamental Clash over Ho...          1  \n",
       "4  President Obama Vetoes 9/11 Victims Bill, Sett...          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article']=df['title']+df['text']\n",
    "df['news_type']=df['id'].apply(lambda x: 1 if x.split('_')[0]=='Real' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gramm count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 10288)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "vectorizer=CountVectorizer()\n",
    "N=vectorizer.fit_transform(df['article'])\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News-user engagement matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 15257)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "row=BFNewsUser[0]-1\n",
    "col=BFNewsUser[1]-1\n",
    "data=BFNewsUser[2]\n",
    "U=csr_matrix((data, (row, col)), shape=(max(row)+1, max(col)+1))\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we use svds built-in function of scipy.sparse library. It stores singular values in ascending order. So we do some modifications after SVD decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import hstack, diags\n",
    "\n",
    "\n",
    "\n",
    "Un,Sn, VnT = svds(N.asfptype())\n",
    "n=len(Sn)\n",
    "Un[:,:n] = Un[:, n-1::-1]\n",
    "Sn = Sn[::-1]\n",
    "VnT[:n, :] = VnT[n-1::-1, :]\n",
    "\n",
    "Uu, Su, VuT = svds(U.asfptype())\n",
    "n=len(Su)\n",
    "Uu[:,:n] = Uu[:, n-1::-1]\n",
    "Su = Su[::-1]\n",
    "VuT[:n, :] = VuT[n-1::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News=csr_matrix(hstack((coo_matrix(Un), coo_matrix(Uu))))\n",
    "SingValue=diags([*Sn, *Su])\n",
    "Weighted_News=News*SingValue\n",
    "Weighted_News.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Weighted_News.copy()\n",
    "Y=df['news_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=.3, random_state=42, shuffle=True, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:42:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:42:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:42:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:43:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:43:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:44:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:44:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:45:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:46:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:46:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "cv=KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "params={\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'n_estimators': (100,500, 50),\n",
    "    'max_features': ('log2', 'sqrt'),\n",
    "    'max_depth': (10,50,10),\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gridXGB=GridSearchCV(XGBClassifier(), param_grid=params, cv=cv, verbose=0)\n",
    "gridXGB.fit(X_train, y_train)\n",
    "y_pred=gridXGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  6]\n",
      " [ 6 21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        28\n",
      "           1       0.78      0.78      0.78        27\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.78      0.78      0.78        55\n",
      "weighted avg       0.78      0.78      0.78        55\n",
      "\n",
      "{'booster': 'gblinear', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 50, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridXGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 10]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.64      0.77        28\n",
      "           1       0.72      0.96      0.83        27\n",
      "\n",
      "    accuracy                           0.80        55\n",
      "   macro avg       0.83      0.80      0.80        55\n",
      "weighted avg       0.84      0.80      0.80        55\n",
      "\n",
      "{'C': 0.01, 'loss': 'hinge', 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "params={\n",
    "    'C': np.array([100,10,1,0.1,0.01,0.001,0.001,0]),\n",
    "    'loss': ('hinge', 'squared_hinge'),\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gridPAC=GridSearchCV(PassiveAggressiveClassifier(), param_grid=params, cv=cv, verbose=0)\n",
    "gridPAC.fit(X_train, y_train)\n",
    "y_pred=gridPAC.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridPAC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  7]\n",
      " [ 6 21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76        28\n",
      "           1       0.75      0.78      0.76        27\n",
      "\n",
      "    accuracy                           0.76        55\n",
      "   macro avg       0.76      0.76      0.76        55\n",
      "weighted avg       0.76      0.76      0.76        55\n",
      "\n",
      "{'C': 0.01, 'loss': 'hinge', 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params={\n",
    "    'penalty':['l2', 'l1'],\n",
    "    'C':np.array([100,10,1,0.1,0.01,0.001,0.001,0])\n",
    "}\n",
    "\n",
    "gridLR=GridSearchCV(LogisticRegression(), param_grid=params, cv=cv, verbose=0)\n",
    "gridLR.fit(X_train, y_train)\n",
    "y_pred=gridLR.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridPAC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler=MaxAbsScaler()\n",
    "scaler.fit(X_train)\n",
    "X_trainN=scaler.transform(X_train)\n",
    "X_testN=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  7]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        28\n",
      "           1       0.77      0.89      0.83        27\n",
      "\n",
      "    accuracy                           0.82        55\n",
      "   macro avg       0.82      0.82      0.82        55\n",
      "weighted avg       0.83      0.82      0.82        55\n",
      "\n",
      "{'C': 100.0, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params={\n",
    "    'penalty':['l2', 'l1'],\n",
    "    'C':np.array([100,10,1,0.1,0.01,0.001,0.001,0])\n",
    "}\n",
    "\n",
    "gridLR=GridSearchCV(LogisticRegression(), param_grid=params, cv=cv, verbose=0)\n",
    "gridLR.fit(X_trainN, y_train)\n",
    "y_pred=gridLR.predict(X_testN)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  5]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88        28\n",
      "           1       0.84      0.96      0.90        27\n",
      "\n",
      "    accuracy                           0.89        55\n",
      "   macro avg       0.90      0.89      0.89        55\n",
      "weighted avg       0.90      0.89      0.89        55\n",
      "\n",
      "{'C': 1.0, 'loss': 'squared_hinge', 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "params={'C': [1.0], 'loss': ['squared_hinge'], 'n_jobs': [-1]}\n",
    "\n",
    "gridPAC=GridSearchCV(PassiveAggressiveClassifier(), param_grid=params, cv=cv, verbose=0)\n",
    "gridPAC.fit(X_trainN, y_train)\n",
    "y_pred=gridPAC.predict(X_testN)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridPAC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "xtest, xval, ytest, yval=train_test_split(X_testN, y_test, test_size=.5, random_state=42, shuffle=True, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "7/7 [==============================] - 1s 20ms/step - loss: 0.6883 - accuracy: 0.4950 - val_loss: 0.6918 - val_accuracy: 0.4615\n",
      "Epoch 2/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.6040 - val_loss: 0.6907 - val_accuracy: 0.5769\n",
      "Epoch 3/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5050 - val_loss: 0.6903 - val_accuracy: 0.5385\n",
      "Epoch 4/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6860 - accuracy: 0.5545 - val_loss: 0.6899 - val_accuracy: 0.5000\n",
      "Epoch 5/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.6436 - val_loss: 0.6892 - val_accuracy: 0.5385\n",
      "Epoch 6/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6833 - accuracy: 0.6139 - val_loss: 0.6888 - val_accuracy: 0.5769\n",
      "Epoch 7/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6818 - accuracy: 0.5941 - val_loss: 0.6881 - val_accuracy: 0.5769\n",
      "Epoch 8/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6774 - accuracy: 0.7030 - val_loss: 0.6870 - val_accuracy: 0.5769\n",
      "Epoch 9/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6756 - accuracy: 0.6634 - val_loss: 0.6860 - val_accuracy: 0.5769\n",
      "Epoch 10/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.6139 - val_loss: 0.6848 - val_accuracy: 0.6154\n",
      "Epoch 11/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6733 - val_loss: 0.6838 - val_accuracy: 0.6538\n",
      "Epoch 12/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.7030 - val_loss: 0.6824 - val_accuracy: 0.6538\n",
      "Epoch 13/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6677 - accuracy: 0.6436 - val_loss: 0.6807 - val_accuracy: 0.6538\n",
      "Epoch 14/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6641 - accuracy: 0.6634 - val_loss: 0.6789 - val_accuracy: 0.6538\n",
      "Epoch 15/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.6238 - val_loss: 0.6769 - val_accuracy: 0.6154\n",
      "Epoch 16/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.6337 - val_loss: 0.6744 - val_accuracy: 0.6154\n",
      "Epoch 17/120\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6466 - accuracy: 0.7327 - val_loss: 0.6721 - val_accuracy: 0.6538\n",
      "Epoch 18/120\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6598 - accuracy: 0.6337 - val_loss: 0.6700 - val_accuracy: 0.6923\n",
      "Epoch 19/120\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6391 - accuracy: 0.7228 - val_loss: 0.6668 - val_accuracy: 0.6538\n",
      "Epoch 20/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6602 - accuracy: 0.6733 - val_loss: 0.6634 - val_accuracy: 0.6538\n",
      "Epoch 21/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6303 - accuracy: 0.7624 - val_loss: 0.6583 - val_accuracy: 0.7308\n",
      "Epoch 22/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6365 - accuracy: 0.7426 - val_loss: 0.6527 - val_accuracy: 0.6923\n",
      "Epoch 23/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6261 - accuracy: 0.7129 - val_loss: 0.6466 - val_accuracy: 0.6923\n",
      "Epoch 24/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6931 - val_loss: 0.6410 - val_accuracy: 0.6923\n",
      "Epoch 25/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6149 - accuracy: 0.7030 - val_loss: 0.6358 - val_accuracy: 0.6923\n",
      "Epoch 26/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6098 - accuracy: 0.7129 - val_loss: 0.6290 - val_accuracy: 0.6923\n",
      "Epoch 27/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.7426 - val_loss: 0.6198 - val_accuracy: 0.6538\n",
      "Epoch 28/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5959 - accuracy: 0.7129 - val_loss: 0.6132 - val_accuracy: 0.6923\n",
      "Epoch 29/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7624 - val_loss: 0.6036 - val_accuracy: 0.6538\n",
      "Epoch 30/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5945 - accuracy: 0.7327 - val_loss: 0.5961 - val_accuracy: 0.6538\n",
      "Epoch 31/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5612 - accuracy: 0.7426 - val_loss: 0.5917 - val_accuracy: 0.6923\n",
      "Epoch 32/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5563 - accuracy: 0.7030 - val_loss: 0.5866 - val_accuracy: 0.6923\n",
      "Epoch 33/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5463 - accuracy: 0.7426 - val_loss: 0.5834 - val_accuracy: 0.6538\n",
      "Epoch 34/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.7624 - val_loss: 0.5768 - val_accuracy: 0.6538\n",
      "Epoch 35/120\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7426 - val_loss: 0.5639 - val_accuracy: 0.6923\n",
      "Epoch 36/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7723 - val_loss: 0.5565 - val_accuracy: 0.6538\n",
      "Epoch 37/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7723 - val_loss: 0.5494 - val_accuracy: 0.6538\n",
      "Epoch 38/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7921 - val_loss: 0.5484 - val_accuracy: 0.6538\n",
      "Epoch 39/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.8020 - val_loss: 0.5435 - val_accuracy: 0.6538\n",
      "Epoch 40/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7624 - val_loss: 0.5347 - val_accuracy: 0.6923\n",
      "Epoch 41/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7624 - val_loss: 0.5313 - val_accuracy: 0.6923\n",
      "Epoch 42/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7426 - val_loss: 0.5272 - val_accuracy: 0.6923\n",
      "Epoch 43/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7426 - val_loss: 0.5256 - val_accuracy: 0.6923\n",
      "Epoch 44/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.8020 - val_loss: 0.5228 - val_accuracy: 0.7308\n",
      "Epoch 45/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.8317 - val_loss: 0.5170 - val_accuracy: 0.7692\n",
      "Epoch 46/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8020 - val_loss: 0.5140 - val_accuracy: 0.7308\n",
      "Epoch 47/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8416 - val_loss: 0.5093 - val_accuracy: 0.7308\n",
      "Epoch 48/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.8317 - val_loss: 0.5084 - val_accuracy: 0.7308\n",
      "Epoch 49/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8119 - val_loss: 0.5068 - val_accuracy: 0.7308\n",
      "Epoch 50/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8416 - val_loss: 0.5015 - val_accuracy: 0.7692\n",
      "Epoch 51/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.8416 - val_loss: 0.5014 - val_accuracy: 0.7692\n",
      "Epoch 52/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8218 - val_loss: 0.5022 - val_accuracy: 0.7308\n",
      "Epoch 53/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8713 - val_loss: 0.5015 - val_accuracy: 0.7308\n",
      "Epoch 54/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8218 - val_loss: 0.4991 - val_accuracy: 0.6923\n",
      "Epoch 55/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7921 - val_loss: 0.4965 - val_accuracy: 0.6923\n",
      "Epoch 56/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7822 - val_loss: 0.4954 - val_accuracy: 0.6923\n",
      "Epoch 57/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8713 - val_loss: 0.4906 - val_accuracy: 0.7308\n",
      "Epoch 58/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7822 - val_loss: 0.4864 - val_accuracy: 0.7308\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7921 - val_loss: 0.4850 - val_accuracy: 0.7692\n",
      "Epoch 60/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8218 - val_loss: 0.4819 - val_accuracy: 0.7308\n",
      "Epoch 61/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8218 - val_loss: 0.4814 - val_accuracy: 0.7308\n",
      "Epoch 62/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8218 - val_loss: 0.4820 - val_accuracy: 0.6923\n",
      "Epoch 63/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8416 - val_loss: 0.4822 - val_accuracy: 0.7308\n",
      "Epoch 64/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3542 - accuracy: 0.8515 - val_loss: 0.4821 - val_accuracy: 0.6923\n",
      "Epoch 65/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8317 - val_loss: 0.4811 - val_accuracy: 0.7692\n",
      "Epoch 66/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8416 - val_loss: 0.4797 - val_accuracy: 0.7308\n",
      "Epoch 67/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8614 - val_loss: 0.4789 - val_accuracy: 0.6923\n",
      "Epoch 68/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8515 - val_loss: 0.4796 - val_accuracy: 0.6923\n",
      "Epoch 69/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8812 - val_loss: 0.4793 - val_accuracy: 0.6923\n",
      "Epoch 70/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8416 - val_loss: 0.4781 - val_accuracy: 0.7308\n",
      "Epoch 71/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8614 - val_loss: 0.4780 - val_accuracy: 0.7308\n",
      "Epoch 72/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.8317 - val_loss: 0.4761 - val_accuracy: 0.6923\n",
      "Epoch 73/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8317 - val_loss: 0.4760 - val_accuracy: 0.7308\n",
      "Epoch 74/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8812 - val_loss: 0.4766 - val_accuracy: 0.7308\n",
      "Epoch 75/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8614 - val_loss: 0.4767 - val_accuracy: 0.7308\n",
      "Epoch 76/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8416 - val_loss: 0.4761 - val_accuracy: 0.7308\n",
      "Epoch 77/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8911 - val_loss: 0.4769 - val_accuracy: 0.7308\n",
      "Epoch 78/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8317 - val_loss: 0.4739 - val_accuracy: 0.7308\n",
      "Epoch 79/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8515 - val_loss: 0.4740 - val_accuracy: 0.7308\n",
      "Epoch 80/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8911 - val_loss: 0.4762 - val_accuracy: 0.7308\n",
      "Epoch 81/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8416 - val_loss: 0.4796 - val_accuracy: 0.7308\n",
      "Epoch 82/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8119 - val_loss: 0.4785 - val_accuracy: 0.6923\n",
      "Epoch 83/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.8911 - val_loss: 0.4811 - val_accuracy: 0.6923\n",
      "Epoch 84/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8614 - val_loss: 0.4808 - val_accuracy: 0.6923\n",
      "Epoch 85/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8416 - val_loss: 0.4839 - val_accuracy: 0.6923\n",
      "Epoch 86/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8713 - val_loss: 0.4789 - val_accuracy: 0.7308\n",
      "Epoch 87/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3137 - accuracy: 0.8515 - val_loss: 0.4790 - val_accuracy: 0.7308\n",
      "Epoch 88/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8812 - val_loss: 0.4813 - val_accuracy: 0.7308\n",
      "Epoch 89/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8515 - val_loss: 0.4797 - val_accuracy: 0.7308\n",
      "Epoch 90/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8515 - val_loss: 0.4789 - val_accuracy: 0.7308\n",
      "Epoch 91/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3134 - accuracy: 0.8713 - val_loss: 0.4854 - val_accuracy: 0.7308\n",
      "Epoch 92/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8218 - val_loss: 0.4889 - val_accuracy: 0.7308\n",
      "Epoch 93/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8416 - val_loss: 0.4857 - val_accuracy: 0.7308\n",
      "Epoch 94/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.8713 - val_loss: 0.4867 - val_accuracy: 0.7308\n",
      "Epoch 95/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.8812 - val_loss: 0.4883 - val_accuracy: 0.7308\n",
      "Epoch 96/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8911 - val_loss: 0.4916 - val_accuracy: 0.6923\n",
      "Epoch 97/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9010 - val_loss: 0.4936 - val_accuracy: 0.6923\n",
      "Epoch 98/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3123 - accuracy: 0.8713 - val_loss: 0.4962 - val_accuracy: 0.6923\n",
      "Epoch 99/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8911 - val_loss: 0.4999 - val_accuracy: 0.6923\n",
      "Epoch 100/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8812 - val_loss: 0.4975 - val_accuracy: 0.6923\n",
      "Epoch 101/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2740 - accuracy: 0.8911 - val_loss: 0.4965 - val_accuracy: 0.7308\n",
      "Epoch 102/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8614 - val_loss: 0.4946 - val_accuracy: 0.7308\n",
      "Epoch 103/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8713 - val_loss: 0.5010 - val_accuracy: 0.7308\n",
      "Epoch 104/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.8713 - val_loss: 0.4990 - val_accuracy: 0.6923\n",
      "Epoch 105/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8614 - val_loss: 0.4965 - val_accuracy: 0.7308\n",
      "Epoch 106/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8812 - val_loss: 0.4996 - val_accuracy: 0.7308\n",
      "Epoch 107/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8614 - val_loss: 0.4980 - val_accuracy: 0.7308\n",
      "Epoch 108/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8614 - val_loss: 0.4955 - val_accuracy: 0.7308\n",
      "Epoch 109/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8911 - val_loss: 0.4965 - val_accuracy: 0.7308\n",
      "Epoch 110/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8812 - val_loss: 0.5009 - val_accuracy: 0.7692\n",
      "Epoch 111/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8416 - val_loss: 0.4919 - val_accuracy: 0.7308\n",
      "Epoch 112/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3135 - accuracy: 0.9010 - val_loss: 0.4874 - val_accuracy: 0.7308\n",
      "Epoch 113/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8713 - val_loss: 0.4886 - val_accuracy: 0.7308\n",
      "Epoch 114/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.9109 - val_loss: 0.4901 - val_accuracy: 0.7308\n",
      "Epoch 115/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2928 - accuracy: 0.9208 - val_loss: 0.4953 - val_accuracy: 0.7308\n",
      "Epoch 116/120\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2829 - accuracy: 0.9010 - val_loss: 0.5062 - val_accuracy: 0.7308\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3051 - accuracy: 0.9109 - val_loss: 0.5175 - val_accuracy: 0.7308\n",
      "Epoch 118/120\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8812 - val_loss: 0.5269 - val_accuracy: 0.7692\n",
      "Epoch 119/120\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8515 - val_loss: 0.5161 - val_accuracy: 0.7308\n",
      "Epoch 120/120\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8812 - val_loss: 0.5053 - val_accuracy: 0.7308\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8181818127632141"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(12,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='linear'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "hist = model.fit(X_trainN.toarray(), y_train,\n",
    "        batch_size=15, epochs=120,\n",
    "        validation_split=.2\n",
    "        )\n",
    "model.evaluate(X_testN.toarray(), y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.81        28\n",
      "           1       0.79      0.85      0.82        27\n",
      "\n",
      "    accuracy                           0.82        55\n",
      "   macro avg       0.82      0.82      0.82        55\n",
      "weighted avg       0.82      0.82      0.82        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_testN.toarray()) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this technique on different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='dataset2/'\n",
    "\n",
    "df=pd.read_csv(path+'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.dropna( how='any', subset=['text'])\n",
    "Y=X['label']\n",
    "X.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.fillna('')\n",
    "X['article']=X['title']+X['author']+X['text']\n",
    "X=X['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "## N-gramm count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 199270)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer= CountVectorizer()\n",
    "N=vectorizer.fit_transform(X)\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import hstack, diags\n",
    "\n",
    "\n",
    "\n",
    "Un,Sn, VnT = svds(N.asfptype())\n",
    "n=len(Sn)\n",
    "Un[:,:n] = Un[:, n-1::-1]\n",
    "Sn = Sn[::-1]\n",
    "VnT[:n, :] = VnT[n-1::-1, :]\n",
    "\n",
    "Weighted_News=Un*diags(Sn)\n",
    "Weighted_News.shape\n",
    "X=Weighted_News.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=.3, random_state=42, shuffle=True, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2471  645]\n",
      " [1181 1932]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      3116\n",
      "           1       0.75      0.62      0.68      3113\n",
      "\n",
      "    accuracy                           0.71      6229\n",
      "   macro avg       0.71      0.71      0.70      6229\n",
      "weighted avg       0.71      0.71      0.70      6229\n",
      "\n",
      "{'C': 100.0, 'loss': 'hinge', 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "params={\n",
    "    'C': np.array([100,10,1,0.1,0.01,0.001,0.001,0]),\n",
    "    'loss': ('hinge', 'squared_hinge'),\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gridPAC=GridSearchCV(PassiveAggressiveClassifier(), param_grid=params, cv=cv, verbose=0)\n",
    "gridPAC.fit(X_train, y_train)\n",
    "y_pred=gridPAC.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridPAC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1926 1190]\n",
      " [ 501 2612]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      3116\n",
      "           1       0.69      0.84      0.76      3113\n",
      "\n",
      "    accuracy                           0.73      6229\n",
      "   macro avg       0.74      0.73      0.73      6229\n",
      "weighted avg       0.74      0.73      0.73      6229\n",
      "\n",
      "{'C': 0.001, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params={\n",
    "    'penalty':['l2'],\n",
    "    'C':np.array([100,10,1,0.1,0.01,0.001,0.001,0]),\n",
    "}\n",
    "\n",
    "gridLR=GridSearchCV(LogisticRegression(), param_grid=params, cv=cv, verbose=0)\n",
    "gridLR.fit(X_train, y_train)\n",
    "y_pred=gridLR.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "scaler=MaxAbsScaler()\n",
    "scaler.fit(X_train)\n",
    "X_trainN=scaler.transform(X_train)\n",
    "X_testN=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1926 1190]\n",
      " [ 503 2610]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      3116\n",
      "           1       0.69      0.84      0.76      3113\n",
      "\n",
      "    accuracy                           0.73      6229\n",
      "   macro avg       0.74      0.73      0.72      6229\n",
      "weighted avg       0.74      0.73      0.72      6229\n",
      "\n",
      "{'C': 100.0, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params={\n",
    "    'penalty':['l2'],\n",
    "    'C':np.array([100,10,1,0.1,0.01,0.001,0.001,0]),\n",
    "    \n",
    "}\n",
    "\n",
    "gridLR=GridSearchCV(LogisticRegression(), param_grid=params, cv=cv, verbose=0)\n",
    "gridLR.fit(X_trainN, y_train)\n",
    "y_pred=gridLR.predict(X_testN)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(gridLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "xtest, xval, ytest, yval=train_test_split(X_testN, y_test, test_size=.5, random_state=42, shuffle=True, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5107 - val_loss: 0.6895 - val_accuracy: 0.5931\n",
      "Epoch 2/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5491 - val_loss: 0.6822 - val_accuracy: 0.6316\n",
      "Epoch 3/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5693 - val_loss: 0.6691 - val_accuracy: 0.6402\n",
      "Epoch 4/120\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.5818 - val_loss: 0.6524 - val_accuracy: 0.6570\n",
      "Epoch 5/120\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6017 - val_loss: 0.6350 - val_accuracy: 0.6729\n",
      "Epoch 6/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6191 - val_loss: 0.6175 - val_accuracy: 0.6797\n",
      "Epoch 7/120\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6384 - val_loss: 0.6039 - val_accuracy: 0.6815\n",
      "Epoch 8/120\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6546 - val_loss: 0.5954 - val_accuracy: 0.6980\n",
      "Epoch 9/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.6639 - val_loss: 0.5794 - val_accuracy: 0.7018\n",
      "Epoch 10/120\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6807 - val_loss: 0.5690 - val_accuracy: 0.7190\n",
      "Epoch 11/120\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5993 - accuracy: 0.6830 - val_loss: 0.5651 - val_accuracy: 0.7224\n",
      "Epoch 12/120\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.6920 - val_loss: 0.5556 - val_accuracy: 0.7224\n",
      "Epoch 13/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6969 - val_loss: 0.5519 - val_accuracy: 0.7234\n",
      "Epoch 14/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.6984 - val_loss: 0.5512 - val_accuracy: 0.7227\n",
      "Epoch 15/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.7061 - val_loss: 0.5483 - val_accuracy: 0.7265\n",
      "Epoch 16/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7044 - val_loss: 0.5478 - val_accuracy: 0.7313\n",
      "Epoch 17/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7100 - val_loss: 0.5473 - val_accuracy: 0.7303\n",
      "Epoch 18/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7128 - val_loss: 0.5421 - val_accuracy: 0.7337\n",
      "Epoch 19/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.7107 - val_loss: 0.5425 - val_accuracy: 0.7313\n",
      "Epoch 20/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7117 - val_loss: 0.5429 - val_accuracy: 0.7303\n",
      "Epoch 21/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7126 - val_loss: 0.5402 - val_accuracy: 0.7327\n",
      "Epoch 22/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7154 - val_loss: 0.5410 - val_accuracy: 0.7317\n",
      "Epoch 23/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7188 - val_loss: 0.5391 - val_accuracy: 0.7334\n",
      "Epoch 24/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7203 - val_loss: 0.5405 - val_accuracy: 0.7337\n",
      "Epoch 25/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7202 - val_loss: 0.5388 - val_accuracy: 0.7337\n",
      "Epoch 26/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7196 - val_loss: 0.5381 - val_accuracy: 0.7293\n",
      "Epoch 27/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7169 - val_loss: 0.5403 - val_accuracy: 0.7327\n",
      "Epoch 28/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7137 - val_loss: 0.5339 - val_accuracy: 0.7341\n",
      "Epoch 29/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7224 - val_loss: 0.5345 - val_accuracy: 0.7310\n",
      "Epoch 30/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7197 - val_loss: 0.5328 - val_accuracy: 0.7334\n",
      "Epoch 31/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7181 - val_loss: 0.5346 - val_accuracy: 0.7355\n",
      "Epoch 32/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7234 - val_loss: 0.5313 - val_accuracy: 0.7362\n",
      "Epoch 33/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7204 - val_loss: 0.5300 - val_accuracy: 0.7313\n",
      "Epoch 34/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7243 - val_loss: 0.5289 - val_accuracy: 0.7355\n",
      "Epoch 35/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7196 - val_loss: 0.5285 - val_accuracy: 0.7331\n",
      "Epoch 36/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7215 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 37/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7203 - val_loss: 0.5262 - val_accuracy: 0.7365\n",
      "Epoch 38/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7217 - val_loss: 0.5259 - val_accuracy: 0.7341\n",
      "Epoch 39/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7201 - val_loss: 0.5285 - val_accuracy: 0.7331\n",
      "Epoch 40/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7215 - val_loss: 0.5299 - val_accuracy: 0.7348\n",
      "Epoch 41/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7251 - val_loss: 0.5260 - val_accuracy: 0.7348\n",
      "Epoch 42/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7206 - val_loss: 0.5259 - val_accuracy: 0.7348\n",
      "Epoch 43/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7219 - val_loss: 0.5243 - val_accuracy: 0.7355\n",
      "Epoch 44/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7226 - val_loss: 0.5196 - val_accuracy: 0.7351\n",
      "Epoch 45/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7203 - val_loss: 0.5232 - val_accuracy: 0.7358\n",
      "Epoch 46/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7329 - val_loss: 0.5251 - val_accuracy: 0.7355\n",
      "Epoch 47/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7270 - val_loss: 0.5180 - val_accuracy: 0.7382\n",
      "Epoch 48/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7260 - val_loss: 0.5184 - val_accuracy: 0.7393\n",
      "Epoch 49/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7207 - val_loss: 0.5205 - val_accuracy: 0.7386\n",
      "Epoch 50/120\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7256 - val_loss: 0.5189 - val_accuracy: 0.7386\n",
      "Epoch 51/120\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7285 - val_loss: 0.5186 - val_accuracy: 0.7375\n",
      "Epoch 52/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7208 - val_loss: 0.5212 - val_accuracy: 0.7300\n",
      "Epoch 53/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7210 - val_loss: 0.5196 - val_accuracy: 0.7375\n",
      "Epoch 54/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7203 - val_loss: 0.5180 - val_accuracy: 0.7389\n",
      "Epoch 55/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5144 - val_accuracy: 0.7355\n",
      "Epoch 56/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7226 - val_loss: 0.5156 - val_accuracy: 0.7379\n",
      "Epoch 57/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7228 - val_loss: 0.5174 - val_accuracy: 0.7358\n",
      "Epoch 58/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7248 - val_loss: 0.5163 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7196 - val_loss: 0.5144 - val_accuracy: 0.7324\n",
      "Epoch 60/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7252 - val_loss: 0.5121 - val_accuracy: 0.7393\n",
      "Epoch 61/120\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7247 - val_loss: 0.5135 - val_accuracy: 0.7379\n",
      "Epoch 62/120\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7240 - val_loss: 0.5133 - val_accuracy: 0.7386\n",
      "Epoch 63/120\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7263 - val_loss: 0.5130 - val_accuracy: 0.7393\n",
      "Epoch 64/120\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7204 - val_loss: 0.5135 - val_accuracy: 0.7365\n",
      "Epoch 65/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7215 - val_loss: 0.5105 - val_accuracy: 0.7382\n",
      "Epoch 66/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7219 - val_loss: 0.5103 - val_accuracy: 0.7393\n",
      "Epoch 67/120\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7214 - val_loss: 0.5106 - val_accuracy: 0.7355\n",
      "Epoch 68/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7235 - val_loss: 0.5069 - val_accuracy: 0.7379\n",
      "Epoch 69/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7233 - val_loss: 0.5095 - val_accuracy: 0.7289\n",
      "Epoch 70/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7234 - val_loss: 0.5098 - val_accuracy: 0.7372\n",
      "Epoch 71/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7233 - val_loss: 0.5083 - val_accuracy: 0.7403\n",
      "Epoch 72/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7273 - val_loss: 0.5087 - val_accuracy: 0.7327\n",
      "Epoch 73/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7196 - val_loss: 0.5080 - val_accuracy: 0.7362\n",
      "Epoch 74/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7177 - val_loss: 0.5055 - val_accuracy: 0.7379\n",
      "Epoch 75/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7203 - val_loss: 0.5077 - val_accuracy: 0.7382\n",
      "Epoch 76/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7207 - val_loss: 0.5073 - val_accuracy: 0.7368\n",
      "Epoch 77/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7240 - val_loss: 0.5092 - val_accuracy: 0.7355\n",
      "Epoch 78/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7217 - val_loss: 0.5075 - val_accuracy: 0.7327\n",
      "Epoch 79/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7142 - val_loss: 0.5054 - val_accuracy: 0.7372\n",
      "Epoch 80/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7217 - val_loss: 0.5070 - val_accuracy: 0.7420\n",
      "Epoch 81/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7203 - val_loss: 0.5049 - val_accuracy: 0.7351\n",
      "Epoch 82/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7174 - val_loss: 0.5078 - val_accuracy: 0.7403\n",
      "Epoch 83/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7157 - val_loss: 0.5071 - val_accuracy: 0.7379\n",
      "Epoch 84/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7231 - val_loss: 0.5057 - val_accuracy: 0.7410\n",
      "Epoch 85/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7209 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
      "Epoch 86/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7163 - val_loss: 0.5067 - val_accuracy: 0.7262\n",
      "Epoch 87/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7178 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 88/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7178 - val_loss: 0.5051 - val_accuracy: 0.7375\n",
      "Epoch 89/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7217 - val_loss: 0.5058 - val_accuracy: 0.7410\n",
      "Epoch 90/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7265 - val_loss: 0.5067 - val_accuracy: 0.7362\n",
      "Epoch 91/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7174 - val_loss: 0.5042 - val_accuracy: 0.7379\n",
      "Epoch 92/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7239 - val_loss: 0.5063 - val_accuracy: 0.7293\n",
      "Epoch 93/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7208 - val_loss: 0.5071 - val_accuracy: 0.7417\n",
      "Epoch 94/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7203 - val_loss: 0.5050 - val_accuracy: 0.7276\n",
      "Epoch 95/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7246 - val_loss: 0.5051 - val_accuracy: 0.7372\n",
      "Epoch 96/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7264 - val_loss: 0.5050 - val_accuracy: 0.7413\n",
      "Epoch 97/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7207 - val_loss: 0.5046 - val_accuracy: 0.7375\n",
      "Epoch 98/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7246 - val_loss: 0.5051 - val_accuracy: 0.7365\n",
      "Epoch 99/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7251 - val_loss: 0.5050 - val_accuracy: 0.7320\n",
      "Epoch 100/120\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7242 - val_loss: 0.5068 - val_accuracy: 0.7393\n",
      "Epoch 101/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7204 - val_loss: 0.5057 - val_accuracy: 0.7296\n",
      "Epoch 102/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7203 - val_loss: 0.5033 - val_accuracy: 0.7362\n",
      "Epoch 103/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7236 - val_loss: 0.5058 - val_accuracy: 0.7355\n",
      "Epoch 104/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7204 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 105/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7165 - val_loss: 0.5037 - val_accuracy: 0.7334\n",
      "Epoch 106/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7223 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 107/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7158 - val_loss: 0.5055 - val_accuracy: 0.7324\n",
      "Epoch 108/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7249 - val_loss: 0.5040 - val_accuracy: 0.7337\n",
      "Epoch 109/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7204 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 110/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7191 - val_loss: 0.5016 - val_accuracy: 0.7379\n",
      "Epoch 111/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7251 - val_loss: 0.5065 - val_accuracy: 0.7234\n",
      "Epoch 112/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7212 - val_loss: 0.5051 - val_accuracy: 0.7303\n",
      "Epoch 113/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7243 - val_loss: 0.5036 - val_accuracy: 0.7307\n",
      "Epoch 114/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7203 - val_loss: 0.5044 - val_accuracy: 0.7293\n",
      "Epoch 115/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7202 - val_loss: 0.5035 - val_accuracy: 0.7368\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7240 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 117/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7266 - val_loss: 0.5029 - val_accuracy: 0.7355\n",
      "Epoch 118/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7202 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
      "Epoch 119/120\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7247 - val_loss: 0.5015 - val_accuracy: 0.7365\n",
      "Epoch 120/120\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7206 - val_loss: 0.5025 - val_accuracy: 0.7300\n",
      "195/195 [==============================] - 0s 623us/step - loss: 0.4823 - accuracy: 0.7486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7485952973365784"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, activation='relu', input_shape=(6,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='linear'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "hist = model.fit(X_trainN, y_train,\n",
    "        batch_size=250, epochs=120,\n",
    "        validation_split=.2\n",
    "        )\n",
    "model.evaluate(X_testN, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      3116\n",
      "           1       0.74      0.78      0.76      3113\n",
      "\n",
      "    accuracy                           0.75      6229\n",
      "   macro avg       0.75      0.75      0.75      6229\n",
      "weighted avg       0.75      0.75      0.75      6229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_testN) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "I have tested lots of models. Here I showed models with better results. Fake News dataset is large unfortunately it doesn't contain information about news-user relationship or user-community relationship. Maybe that's why I didn't get so good results. <br>\n",
    "To sum up, applying SVD factorization to dataset makes our life easier. Because not so neccaserly doing feature engineering which takes much time and get good results."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7468e57abf7d5b9340a16098e435666f9c96d34b7301cab84f60b4d98dbeb517"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
